{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5332e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a29e582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c6ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "Stw = set(stopwords.words('english')) #stopwords in english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac1084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "#reading a .txt file and returning a dictianary of words \n",
    "def Word_freq(path_art):\n",
    "\n",
    "# Open the file in read mode\n",
    "\n",
    "    with open(path_art, \"r\",encoding='Windows-1252') as text:\n",
    "\n",
    "        # Create an empty dictionary\n",
    "        d = {}\n",
    "\n",
    "        # Loop through each line of the file\n",
    "        l=0\n",
    "        for line in text:\n",
    "            l+=1\n",
    "            if l<15:\n",
    "                continue\n",
    "\n",
    "            #print(type(line))\n",
    "            # Remove the leading spaces and newline character\n",
    "            line = line.strip()\n",
    "\n",
    "            # Convert the characters in line to\n",
    "            # lowercase to avoid case mismatch\n",
    "            line = line.lower()\n",
    "\n",
    "            # Remove the punctuation marks from the line\n",
    "            line = line.translate(line.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "            # Split the line into words\n",
    "            words = line.split(\" \")\n",
    "\n",
    "            # Iterate over each word in line\n",
    "            \n",
    "            for word in words:\n",
    "                #vomit the word if the word is stopword or numeric\n",
    "                if word in Stw or word.isnumeric() or word=='' or word==' ':\n",
    "                    continue\n",
    "                # Check if the word is already in dictionary \n",
    "                if word in d:\n",
    "                    # Increment count of word by 1\n",
    "                    d[word] = d[word] + 1\n",
    "                else:\n",
    "                    # Add the word to dictionary with count 1\n",
    "                    d[word] = 1\n",
    "\n",
    "        return d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7492c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = r\"20_newsgroups\"\n",
    "List_sub = os.listdir(path_root)\n",
    "\n",
    "dict_freq = {}\n",
    "total_files =0\n",
    "#traversing through files of news articles\n",
    "for sub in List_sub:\n",
    "    path_sub = path_root+\"\\\\\"+sub\n",
    "    List_art = os.listdir(path_sub)\n",
    "    for art in List_art:\n",
    "        path_art = path_sub + \"\\\\\" + art\n",
    "        total_files+=1\n",
    "        d = Word_freq(path_art)\n",
    "        for key in d:\n",
    "            if key not in dict_freq:\n",
    "                dict_freq[key]=0\n",
    "            dict_freq[key]+=d[key]\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea893fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of features(words) whose frequency is greater that 4\n",
    "Feature =[] \n",
    "for key in dict_freq:\n",
    "    if dict_freq[key] > 4:\n",
    "        Feature.append([key,dict_freq[key]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33c34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.sort( key = lambda x: x[1], reverse=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c804580",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_indx ={}\n",
    "Feature_ls=[]\n",
    "for i in range(len(Feature)):\n",
    "    Feature_indx[Feature[i][0]]=i\n",
    "    Feature_ls.append(Feature[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff38f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing a clean dataset\n",
    "def process_text(path_root):\n",
    "    List_sub = os.listdir(path_root)\n",
    "    data_tr_ls=[]\n",
    "    tabular_result=[]\n",
    "    for sub in List_sub:\n",
    "        path_sub = path_root+\"\\\\\"+sub\n",
    "        List_art = os.listdir(path_sub)\n",
    "        for art in List_art:\n",
    "            path_art = path_sub + \"\\\\\" + art\n",
    "            d = Word_freq(path_art)\n",
    "            art_ls=[0]*len(Feature_ls)\n",
    "            for key in d:\n",
    "                if key in Feature_indx:\n",
    "                    ind = Feature_indx[key]\n",
    "                    art_ls[ind]+=1\n",
    "            data_tr_ls.append(art_ls)\n",
    "            tabular_result.append(sub)\n",
    "    return data_tr_ls, tabular_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82aa68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = r\"20_newsgroups\"\n",
    "data_tr_ls, data_result_ls =  process_text(path_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a9df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = np.array(data_tr_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d55dedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del data_tr_ls\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict ={}\n",
    "result_num_to_str_map=[]\n",
    "for i in range(len(data_result_ls)):\n",
    "    if data_result_ls[i] not in result_dict:\n",
    "        result_num_to_str_map.append(data_result_ls[i])\n",
    "        result_dict[data_result_ls[i]] = len(result_dict)\n",
    "    data_result_ls[i]= result_dict[data_result_ls[i]]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ec5daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result = np.array(data_result_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df4fd3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_result_ls\n",
    "del Feature\n",
    "del Feature_ls\n",
    "del dict_freq\n",
    "del result_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76a7ac",
   "metadata": {},
   "source": [
    "Now 'data_target' & 'data_result' is final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3774009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data_target, data_result,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30f8e2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_result\n",
    "del data_target\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e66f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89d433",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes made from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a64e2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mult_NB:\n",
    "\n",
    "\n",
    "    def fit(self, X_train , Y_train):\n",
    "        total_classes = len(set(Y_train))\n",
    "        self.count_arr = np.ones((total_classes, X_train.shape[1]))\n",
    "        self.count_in_1class = np.full( (total_classes,) ,X_train.shape[1])\n",
    "        self.class_freq  = np.zeros((total_classes,))\n",
    "        self.train_size= Y_train.shape[0]\n",
    "        for i in range(Y_train.shape[0]):\n",
    "            for j in range(X_train.shape[1]):\n",
    "                self.count_arr[Y_train[i]][j]+=X_train[i][j]\n",
    "                self.count_in_1class[Y_train[i]] += X_train[i][j]\n",
    "            self.class_freq[Y_train[i]]+=1\n",
    "        \n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        Y_pred = np.zeros(X_test.shape[0])\n",
    "        for i in range(Y_pred.shape[0]):\n",
    "            max_prob=-1\n",
    "            predic=-1\n",
    "            first_itr= True\n",
    "            for possible_pred in range(self.class_freq.shape[0]):\n",
    "                prob_local=0\n",
    "                for j in range(X_test.shape[1]):\n",
    "                    if X_test[i][j]>0:\n",
    "                        prob_local += math.log(self.count_arr[possible_pred][j] / self.count_in_1class[possible_pred])\n",
    "                    else:\n",
    "                        prob_local += math.log(1 - ( self.count_arr[possible_pred][j] / self.count_in_1class[possible_pred] )  )\n",
    "                prob_local+= math.log(self.class_freq[possible_pred] / self.train_size)\n",
    "                if first_itr or prob_local > max_prob:\n",
    "                    max_prob= prob_local\n",
    "                    predic = possible_pred\n",
    "                    first_itr = False\n",
    "            Y_pred[i]=predic\n",
    "        return Y_pred\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f7cc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scratch = Mult_NB()\n",
    "clf_scratch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2127cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_scratch = clf_scratch.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbdfcac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report of model made from scratch:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.65      0.74      0.69        87\n",
      "           comp.graphics       0.73      0.67      0.70       111\n",
      " comp.os.ms-windows.misc       0.79      0.80      0.79       105\n",
      "comp.sys.ibm.pc.hardware       0.63      0.65      0.64        98\n",
      "   comp.sys.mac.hardware       0.72      0.71      0.72        89\n",
      "          comp.windows.x       0.74      0.77      0.76        96\n",
      "            misc.forsale       0.78      0.73      0.75       115\n",
      "               rec.autos       0.86      0.87      0.87        86\n",
      "         rec.motorcycles       0.95      0.91      0.93       102\n",
      "      rec.sport.baseball       0.95      0.85      0.89       110\n",
      "        rec.sport.hockey       0.88      0.93      0.90        84\n",
      "               sci.crypt       0.91      0.90      0.91        93\n",
      "         sci.electronics       0.81      0.69      0.75        94\n",
      "                 sci.med       0.92      0.88      0.90       121\n",
      "               sci.space       0.94      0.88      0.91       109\n",
      "  soc.religion.christian       0.85      0.84      0.84       118\n",
      "      talk.politics.guns       0.81      0.93      0.86       109\n",
      "   talk.politics.mideast       0.57      0.94      0.71        81\n",
      "      talk.politics.misc       0.81      0.67      0.74       101\n",
      "      talk.religion.misc       0.50      0.42      0.46        91\n",
      "\n",
      "                accuracy                           0.79      2000\n",
      "               macro avg       0.79      0.79      0.79      2000\n",
      "            weighted avg       0.80      0.79      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"report of model made from scratch:\")\n",
    "print(classification_report(Y_test, Y_pred_scratch, target_names=result_num_to_str_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf99e7",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes by using sklearn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25b8514e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5a786dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred= clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0666b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report of model by using sklearn:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.65      0.74      0.69        87\n",
      "           comp.graphics       0.73      0.67      0.70       111\n",
      " comp.os.ms-windows.misc       0.79      0.80      0.79       105\n",
      "comp.sys.ibm.pc.hardware       0.63      0.65      0.64        98\n",
      "   comp.sys.mac.hardware       0.72      0.71      0.72        89\n",
      "          comp.windows.x       0.74      0.77      0.76        96\n",
      "            misc.forsale       0.78      0.73      0.75       115\n",
      "               rec.autos       0.86      0.87      0.87        86\n",
      "         rec.motorcycles       0.95      0.91      0.93       102\n",
      "      rec.sport.baseball       0.95      0.85      0.89       110\n",
      "        rec.sport.hockey       0.88      0.93      0.90        84\n",
      "               sci.crypt       0.91      0.90      0.91        93\n",
      "         sci.electronics       0.81      0.69      0.75        94\n",
      "                 sci.med       0.92      0.88      0.90       121\n",
      "               sci.space       0.94      0.88      0.91       109\n",
      "  soc.religion.christian       0.85      0.84      0.84       118\n",
      "      talk.politics.guns       0.81      0.93      0.86       109\n",
      "   talk.politics.mideast       0.57      0.94      0.71        81\n",
      "      talk.politics.misc       0.81      0.67      0.74       101\n",
      "      talk.religion.misc       0.50      0.42      0.46        91\n",
      "\n",
      "                accuracy                           0.79      2000\n",
      "               macro avg       0.79      0.79      0.79      2000\n",
      "            weighted avg       0.80      0.79      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"report of model by using sklearn:\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=result_num_to_str_map))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
